{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19169349-1712-456a-983a-1ab4edfb6b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import Ollama\n",
    "import bs4\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "from langchain_core.messages import AIMessage, HumanMessage, BaseMessage\n",
    "from langchain_community.vectorstores import DocArrayInMemorySearch\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_community.document_loaders import WebBaseLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13133579-00df-4800-b1ba-214ba5d99e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Ollama(model=\"llama2\")\n",
    "embeddings_provider = OllamaEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3846165-28a8-4710-9d50-046cf754743f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = WebBaseLoader(\n",
    "    [\"https://lilianweng.github.io/posts/2023-06-23-agent/\"\n",
    "     ]\n",
    ")\n",
    "\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af21b10b-bb46-4674-ba5d-d431d89843f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter()\n",
    "document_chunks = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b444643b-3840-480f-bf78-230b26af9740",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = DocArrayInMemorySearch.from_documents(document_chunks, embeddings_provider)\n",
    "retriever = vector_store.as_retriever()\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b782f90c-5805-45c0-8ab1-dd56811f7711",
   "metadata": {},
   "outputs": [],
   "source": [
    "contextualize_q_system_prompt = \"\"\"Given a chat history and the latest user question \\\n",
    "which might reference context in the chat history, formulate a standalone question \\\n",
    "which can be understood without the chat history. Do NOT answer the question, \\\n",
    "just reformulate it if needed and otherwise return it as is.\"\"\"\n",
    "\n",
    "contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", contextualize_q_system_prompt),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "592c6bc6-d43d-4dff-9e2f-c33126aa5293",
   "metadata": {},
   "outputs": [],
   "source": [
    "contextualize_q_chain = contextualize_q_prompt | llm | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c239416c-ade7-480b-be49-96a327ca32d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_system_prompt = \"\"\"You are an assistant for question-answering tasks. \\\n",
    "Use the following pieces of retrieved context to answer the question. \\\n",
    "If you don't know the answer, just say that you don't know. \\\n",
    "Use three sentences maximum and keep the answer concise.\\\n",
    "\n",
    "{context}\"\"\"\n",
    "qa_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", qa_system_prompt),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c28315df-1999-46d0-8d04-f8c90ac8e2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contextualized_question(input: dict):\n",
    "    if input.get(\"chat_history\"):\n",
    "        return contextualize_q_chain\n",
    "    else:\n",
    "        return input[\"question\"]\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04a703c1-1830-4e8c-b018-9bdb383fd990",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain = (\n",
    "        RunnablePassthrough.assign(\n",
    "            context=contextualized_question | retriever | format_docs\n",
    "        )\n",
    "        | qa_prompt\n",
    "        | llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7508be31-de6c-49e4-9d3a-29ba99ad8c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A large language model (LLM) is a type of artificial intelligence (AI) model that is trained on a large corpus of text data to generate language outputs that are coherent and natural-sounding. LLMs are typically trained using deep learning algorithms, such as transformers, and can be used for a variety of natural language processing tasks, such as language translation, text summarization, and language generation.\n",
      "\n",
      "LLMs have been shown to be highly effective at generating coherent and contextually appropriate text, and have the potential to revolutionize many areas of natural language processing. For example, LLMs could be used to generate chatbot responses that are tailored to the user's input, or to generate automated summaries of long documents.\n",
      "\n",
      "There are several different types of LLMs, including:\n",
      "\n",
      "1. Language Translation Models: These models are trained to translate text from one language to another. They can be used to translate text in real-time, or to generate translations of large amounts of text.\n",
      "2. Text Summarization Models: These models are trained to summarize long documents or articles into shorter summaries that capture the main points.\n",
      "3. Language Generation Models: These models are trained to generate coherent and contextually appropriate text, such as chatbot responses or automated content generation.\n",
      "4. Question Answering Models: These models are trained to answer questions based on a given text passage or corpus of text.\n",
      "5. Dialogue Systems: These models are trained to engage in conversation with a human, and can be used to generate responses to user input.\n",
      "\n",
      "The key advantages of LLMs include their ability to generate coherent and contextually appropriate text, as well as their potential to automate many areas of natural language processing. However, there are also some challenges and limitations to consider when using LLMs, such as the need for large amounts of training data and the potential for bias or errors in the generated text.\n"
     ]
    }
   ],
   "source": [
    "chat_history = []\n",
    "\n",
    "question = \"What is a large language model?\"\n",
    "ai_msg = rag_chain.invoke({\"question\": question, \"chat_history\": chat_history})\n",
    "print(ai_msg)\n",
    "chat_history.extend([HumanMessage(content=question), AIMessage(content=ai_msg)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c668bb32-9830-49e8-9313-46e581ff71c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: Sure! When we refer to a language model as \"large,\" we are typically talking about the size of its training dataset and the complexity of the algorithms used to train it.\n",
      "\n",
      "Large language models are trained on massive datasets that contain billions or even trillions of words. This allows the model to learn patterns and relationships in language that would be difficult or impossible to capture with smaller datasets. For example, a large language model trained on a dataset of millions of books could generate coherent and contextually appropriate text that is comparable to human-written text.\n",
      "\n",
      "The size of the training dataset is important because it determines how much information the model can learn from the data. The more data the model has to learn from, the better it can generalize to new situations and generate coherent and natural-sounding text.\n",
      "\n",
      "In addition to the size of the training dataset, the complexity of the algorithms used to train the model is also important. Deep learning algorithms such as transformers are capable of capturing complex patterns in language, but they require large amounts of data and computational resources to train. As a result, large language models are typically more accurate and able to generate more coherent text than smaller models.\n",
      "\n",
      "Overall, the term \"large\" refers to both the size of the training dataset and the complexity of the algorithms used to train the model. By combining these factors, large language models have the potential to revolutionize many areas of natural language processing.\n"
     ]
    }
   ],
   "source": [
    "second_question = \"Can you explain the reasoning behind calling it large?\"\n",
    "second_answer = rag_chain.invoke({\"question\": second_question, \"chat_history\": chat_history})\n",
    "print(second_answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chapter10",
   "language": "python",
   "name": "chapter10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
