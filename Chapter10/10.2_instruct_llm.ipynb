{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b64ad5a-620c-40cf-86cc-c5ab64eaec25",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7afd9b74-113c-438c-87ec-c03d2e48c3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, GenerationConfig, logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e5ed30d-fac4-4c62-9236-9c90bf1b7ca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: fineGrained).\n",
      "Your token has been saved to /home/saurabh/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "# This recipe requires a HuggingFace token to access the mistral models from the hub. You will need to create a HuggingFace login\n",
    "# and generate a token for use at https://huggingface.co/settings/tokens. You will also need to visit the model card at \n",
    "# https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.1 and accept the terms to use the model. Once you have generated the token,\n",
    "# save it in an environment variable named HUGGINGFACE_TOKEN and read it in the recipe as shown in the snippet below.\n",
    "from huggingface_hub import login\n",
    "hf_token = os.environ.get('HUGGINGFACE_TOKEN')\n",
    "login(token=hf_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ffcb58b-2d36-4d62-bfe1-5f43cb1c2095",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.set_verbosity_error()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11eb1f98-9eac-4abd-a501-4561ce90857c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.1\", device_map=\"auto\", \n",
    "                                             load_in_4bit=True, torch_dtype=torch.float16)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cad9f6d8-c2f9-4d9f-8fc0-5a53ee0ef2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = [\n",
    "    {\"role\": \"user\", \"content\": \"What is your favourite country?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Well, I am quite fascinated with Peru.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What can you tell me about Peru?\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "635ff3ad-812e-471a-9fd5-f60de6db341f",
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_config = GenerationConfig(\n",
    "    num_beams=4,\n",
    "    early_stopping=True,\n",
    "    eos_token_id=model.config.eos_token_id,\n",
    "    pad_token_id=model.config.eos_token_id,\n",
    "    max_new_tokens=900,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43ce9b4-a79d-4d12-b52f-8d9113a87d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_prompt = tokenizer.apply_chat_template(prompt, return_tensors=\"pt\")\n",
    "model_inputs = encoded_prompt.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40dd256d-8611-4e4f-bf9d-d4c16f944826",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_ids = model.generate(model_inputs, max_new_tokens=1000, do_sample=True,\n",
    "                               generation_config=generation_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1a27120-dbc9-4e6f-bade-92af3cf8a442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> [INST] What is your favourite country? [/INST]Well, I am quite fascinated with Peru.</s>  [INST] What can you tell me about Peru? [/INST] Peru is a country located in South America. It is bordered by Ecuador to the north, Colombia to the northeast, Brazil to the east, Bolivia and Chile to the south, and the Pacific Ocean to the west. Peru is known for its diverse geography, which includes the Andes Mountains, the Amazon Rainforest, and the Pacific coastline.\n",
      "\n",
      "Peru is also known for its rich history and culture. The country was once home to several pre-Columbian civilizations, including the Inca Empire, which was one of the largest and most advanced civilizations in the world at the time of its collapse in the 16th century.\n",
      "\n",
      "Today, Peru is a popular tourist destination, known for its stunning natural beauty, ancient ruins, and vibrant culture. Some of the top attractions in Peru include Machu Picchu, the Amazon Rainforest, and the Nazca Lines. The country is also known for its delicious cuisine, which includes dishes such as ceviche, lomo saltado, and chupe de mariscos.</s>\n"
     ]
    }
   ],
   "source": [
    "decoded = tokenizer.batch_decode(generated_ids)\n",
    "print(decoded[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e1ae623-d8fc-4d32-820a-7560394efa8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = [\n",
    "    {\"role\": \"user\", \"content\": \"Mary is twice as old as Sarah presently. Sarah is 6 years old.?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Well, what can I help you with?\"},\n",
    "    {\"role\": \"user\", \"content\": \"Can you tell me in a step by step way on how old Mary will be after 5 years?\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e651278d-552a-4637-bf80-c085a37b7250",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using sep_token, but it is not set yet.\n",
      "Using pad_token, but it is not set yet.\n",
      "Using cls_token, but it is not set yet.\n",
      "Using mask_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> [INST] Mary is twice as old as Sarah presently. Sarah is 6 years old.? [/INST]Well, what can I help you with?</s>  [INST] Can you tell me in a step by step way on how old Mary will be after 5 years? [/INST] Sure! Here's a step-by-step calculation:\n",
      "\n",
      "1. Sarah is currently 6 years old.\n",
      "2. Mary is twice as old as Sarah, so Mary is currently 6 x 2 = 12 years old.\n",
      "3. After 5 years, Mary will be 12 + 5 = 17 years old.\n",
      "\n",
      "So, Mary will be 17 years old after 5 years.</s>\n"
     ]
    }
   ],
   "source": [
    "encoded_prompt = tokenizer.apply_chat_template(prompt, return_tensors=\"pt\")\n",
    "model_inputs = encoded_prompt.to(device)\n",
    "generated_ids = model.generate(model_inputs, max_new_tokens=1000, do_sample=True,\n",
    "                               generation_config=generation_config)\n",
    "decoded = tokenizer.batch_decode(generated_ids)\n",
    "print(decoded[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchgpu",
   "language": "python",
   "name": "torchgpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
